---
title: "Predicting Future Sales"
description: ""
author: "Brian Cervantes Alvarez"
date: "06-04-2023"
format:
  html:
    toc: true
    toc-location: right
    html-math-method: katex
    page-layout: full
execute: 
  warning: false
  message: false
categories: [Python, Machine Learning]
jupyter: python3
---

# Load Libraries
```{python}
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
```

```{python}
games = pd.read_csv("MlDataset.csv")
```


## Data Exploration
```{python}

# Full Plot
sns.boxplot(data=games[['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']])
plt.title('Game Sales Distribution')
plt.ylabel('Sales (in millions)')
plt.xlabel('Regions')
plt.show()

# Limit to 30 million

sns.boxplot(data=games[['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']])
plt.title('Game Sales Distribution')
plt.ylabel('Sales (in millions)')
plt.xlabel('Regions')
plt.ylim(0, 30)
plt.show()



# Limit to 1 million

sns.boxplot(data=games[['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']])
plt.title('Game Sales Distribution')
plt.ylabel('Sales (in millions)')
plt.xlabel('Regions')
plt.ylim(0, 1)
plt.show()

```


# Data Wrangling
```{python}
games.head(5)
games['Publisher'].nunique()
games['Developer'].nunique()


# Convert Year column into INT. To be used as a dummy column
games['Year_of_Release'] = games['Year_of_Release'].astype(int)
games['Year_of_Release'].unique()
games.head(5)
games.columns


games.drop(['Name', 'Year_of_Release'], axis=1, inplace=True)
games.head(5)

dummy_cols = ['Platform', 'Year_of_Release', 'Genre', 'Publisher', 'Developer', 'Rating']

games.columns
# Creating dummy columns
games = pd.get_dummies(games, columns=dummy_cols)

# Printing the modified DataFrame with dummy columns
#print(games_with_dummies)
games.shape
games.head(5)

```


## Tensorflow Model
```{python}
tf.random.set_seed(42)

# Step 1: Preparing the Data
X = games.drop(['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales'], axis=1)
y = games[['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']] # Target

scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Step 2: Building the Neural Network Model
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(y_train.shape[1])  # Output layer with the number of sales columns as the units
])

model.compile(loss='mse', optimizer='adam')  # Adjust the loss function and optimizer as needed

# Step 3: Training the Model
model.fit(X_train, y_train, epochs=50, batch_size=32)  # Adjust the number of epochs and batch size as needed

# Step 4: Evaluating and Making Predictions
loss = model.evaluate(X_test, y_test)
predictions = model.predict(X_test)

# Evaluation Metrics
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, predictions)
r2 = r2_score(y_test, predictions)

print("Tensorflow Model:")
print("Test Loss (MSE):", loss)
print("RMSE:", rmse)
print("MAE:", mae)
print("R-squared:", r2)

```

# Feature Importance
```{python}
from sklearn.inspection import permutation_importance

# Get the weights of the model's layers
weights = model.get_weights()

# Calculate the absolute sum of weights for each feature
feature_weights = np.abs(weights[0]).sum(axis=0)

# Create a list of (feature, weight) tuples
feature_weight_tuples = list(zip(X.columns, feature_weights))

# Sort the list by weight in descending order
feature_weight_tuples.sort(key=lambda x: x[1], reverse=True)

# Extract the top 10 features
top_10_features = [feature for feature, weight in feature_weight_tuples[:10]]

# Print the top 10 features
print("Top 10 Features:")
for feature, weight in feature_weight_tuples[:10]:
    print(f"{feature}: {weight}")

```

## Visualizing Tensorflow Model
```{python}
plt.figure(figsize=(8, 6))

# For Global_Sales
plt.scatter(y_test['Global_Sales'], predictions[:, 0], alpha=0.5, label='Predicted', color='blue')
plt.scatter(y_test['Global_Sales'], y_test['Global_Sales'], alpha=0.5, label='Actual', color='red')
plt.xlabel('Actual Global Sales')
plt.ylabel('Predicted Global Sales')
plt.title('Actual vs. Predicted Global Sales')
plt.legend()
plt.show()


# For NA_Sales
plt.scatter(y_test['NA_Sales'], predictions[:, 0], alpha=0.5, label='Predicted', color='blue')
plt.scatter(y_test['NA_Sales'], y_test['NA_Sales'], alpha=0.5, label='Actual', color='red')
plt.xlabel('Actual NA Sales')
plt.ylabel('Predicted NA Sales')
plt.title('Actual vs. Predicted NA Sales')
plt.legend()
plt.show()

# For EU_Sales
plt.figure(figsize=(8, 6))
plt.scatter(y_test['EU_Sales'], predictions[:, 1], alpha=0.5, label='Predicted', color='blue')
plt.scatter(y_test['EU_Sales'], y_test['EU_Sales'], alpha=0.5, label='Actual', color='red')
plt.xlabel('Actual EU Sales')
plt.ylabel('Predicted EU Sales')
plt.title('Actual vs. Predicted EU Sales')
plt.legend()
plt.show()

# For JP_Sales
plt.figure(figsize=(8, 6))
plt.scatter(y_test['JP_Sales'], predictions[:, 2], alpha=0.5, label='Predicted', color='blue')
plt.scatter(y_test['JP_Sales'], y_test['JP_Sales'], alpha=0.5, label='Actual', color='red')
plt.xlabel('Actual JP Sales')
plt.ylabel('Predicted JP Sales')
plt.title('Actual vs. Predicted JP Sales')
plt.legend()
plt.show()

# For Other_Sales
plt.figure(figsize=(8, 6))
plt.scatter(y_test['Other_Sales'], predictions[:, 3], alpha=0.5, label='Predicted', color='blue')
plt.scatter(y_test['Other_Sales'], y_test['Other_Sales'], alpha=0.5, label='Actual', color='red')
plt.xlabel('Actual Other Sales')
plt.ylabel('Predicted Other Sales')
plt.title('Actual vs. Predicted Other Sales')
plt.legend()
plt.show()

```

```{python}
# Random Forest Model

np.random.seed(42)

# Random Forest Model
rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X_train, y_train)

rf_predictions = rf_model.predict(X_test)
rf_mse = mean_squared_error(y_test, rf_predictions)
rf_rmse = np.sqrt(rf_mse)
rf_mae = mean_absolute_error(y_test, rf_predictions)
rf_r2 = r2_score(y_test, rf_predictions)

print("Random Forest Model:")
print("MSE:", rf_mse)
print("RMSE:", rf_rmse)
print("MAE:", rf_mae)
print("R-squared:", rf_r2)

# XGBoost Model
xgb_model = xgb.XGBRegressor(random_state=42)
xgb_model.fit(X_train, y_train)

xgb_predictions = xgb_model.predict(X_test)
xgb_mse = mean_squared_error(y_test, xgb_predictions)
xgb_rmse = np.sqrt(xgb_mse)
xgb_mae = mean_absolute_error(y_test, xgb_predictions)
xgb_r2 = r2_score(y_test, xgb_predictions)

print("\nXGBoost Model:")
print("MSE:", xgb_mse)
print("RMSE:", xgb_rmse)
print("MAE:", xgb_mae)
print("R-squared:", xgb_r2)

# Linear Regression Model
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)

linear_predictions = linear_model.predict(X_test)
linear_mse = mean_squared_error(y_test, linear_predictions)
linear_rmse = np.sqrt(linear_mse)
linear_mae = mean_absolute_error(y_test, linear_predictions)
linear_r2 = r2_score(y_test, linear_predictions)

print("\nLinear Regression Model:")
print("MSE:", linear_mse)
print("RMSE:", linear_rmse)
print("MAE:", linear_mae)
print("R-squared:", linear_r2)
```
